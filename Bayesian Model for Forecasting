import bambi as bmb
import matplotlib.pyplot as plt
import numpy as np
import pandas as pd
import pymc as pm
import seaborn as sns

sns.set(style="darkgrid", palette="muted")

def simulate_linear_data(
    start, stop, N, beta_0, beta_1, eps_mean, eps_sigma_sq
):
    
    df = pd.DataFrame(
        {"x": 
            np.linspace(start, stop, num=N)
        }
    )
    
    df["y"] = beta_0 + beta_1*df["x"] + np.random.RandomState(s).normal(
        eps_mean, eps_sigma_sq, N
    )
    return df


def plot_simulated_data(df):
   
    sns.lmplot(x="x", y="y", data=df, height=10)
    plt.xlim(0.0, 1.0)
    plt.show()


def glm_mcmc_inference(df, iterations=5000):

    model = bmb.Model("y ~ x", df)
 
    trace = model.fit(
        draws=5000,
        tune=500,
        discard_tuned_samples=True,
        chains=1, 
        progressbar=True)
    return trace


def plot_glm_model(trace):
    pm.plot_trace(trace)
    plt.tight_layout()
    plt.show()


def plot_regression_lines(trace, df, N):
    fig, ax = plt.subplots(figsize=(7, 7))
    x = np.linspace(0, 1, N)
    ax.scatter(df['x'], df['y'])
    intercepts = trace.posterior.Intercept.to_numpy()[0]
    slopes = trace.posterior.x.to_numpy()[0]
    sample_indexes = np.random.randint(len(intercepts), size=100)
    for i in sample_indexes:
        y_line = intercepts[i] + slopes[i] * x
        ax.plot(x, y_line, c='black', alpha=0.07)
    y = beta_0 + beta_1*x
    ax.plot(x, y, label="True Regression Line", lw=3., c="green")
    ax.legend(loc=0)
    ax.set_xlim(0.0, 1.0)
    ax.set_ylim(0.0, 4.0)
    plt.show()


if __name__ == "__main__":
    beta_0 = 1.0  
    beta_1 = 2.0  

    start = 0
    stop = 1
    N = 100
    eps_mean = 0.0
    eps_sigma_sq = 0.5

    s = 42

    df = simulate_linear_data(
        start, stop, N, beta_0, beta_1, eps_mean, eps_sigma_sq
    )
    plot_simulated_data(df)
 
    trace = glm_mcmc_inference(df, iterations=5000)
    plot_glm_model(trace)
    plot_regression_lines(trace, df, N)
